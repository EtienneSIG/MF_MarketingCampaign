# Guide de DÃ©ploiement - Microsoft Fabric (ScÃ©nario Marketing Campaigns)

## ðŸŽ¯ Objectif

Ce guide dÃ©crit **Ã©tape par Ã©tape** comment dÃ©ployer la dÃ©mo Customer 360 + CRM + Marketing Campaigns + Commerce dans Microsoft Fabric.

**PrÃ©requis** :
- Un compte Microsoft Fabric (trial ou licence)
- Les donnÃ©es gÃ©nÃ©rÃ©es localement (voir README.md)
- Un workspace Fabric crÃ©Ã©

**DurÃ©e estimÃ©e** : 45-60 minutes

---

## ðŸ“‹ Vue d'Ensemble du DÃ©ploiement

```
Ã‰tape 1: CrÃ©er un Lakehouse
Ã‰tape 2: Uploader les donnÃ©es vers OneLake
Ã‰tape 3: CrÃ©er des OneLake Shortcuts
Ã‰tape 4: Appliquer Shortcut Transformations AI sur les textes
Ã‰tape 5: Charger les CSV en tables Delta
Ã‰tape 6: CrÃ©er un Semantic Model
Ã‰tape 7: Configurer le Fabric Data Agent
Ã‰tape 8: Tester et valider
```

---

## Ã‰tape 1 : CrÃ©er un Lakehouse

### 1.1 AccÃ©der au Workspace

1. Ouvrir [Microsoft Fabric](https://app.fabric.microsoft.com/)
2. SÃ©lectionner ou crÃ©er un workspace (ex: `Demo-Marketing360`)
3. VÃ©rifier que vous Ãªtes dans l'expÃ©rience **Data Engineering**

### 1.2 CrÃ©er le Lakehouse

1. Cliquer sur **+ New** â†’ **Lakehouse**
2. Nom : `Marketing360_Lakehouse`
3. Cliquer sur **Create**

âœ… **RÃ©sultat attendu** : Un Lakehouse vide avec deux sections : **Tables** et **Files**.

---

## Ã‰tape 2 : Uploader les DonnÃ©es vers OneLake

### 2.1 PrÃ©parer les DonnÃ©es Locales

Sur votre machine locale, les donnÃ©es gÃ©nÃ©rÃ©es sont dans :
```
data/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ crm/
â”‚   â”‚   â”œâ”€â”€ accounts.csv
â”‚   â”‚   â”œâ”€â”€ customers.csv
â”‚   â”‚   â”œâ”€â”€ segments.csv
â”‚   â”‚   â”œâ”€â”€ customer_segments.csv
â”‚   â”‚   â”œâ”€â”€ interactions.csv
â”‚   â”‚   â””â”€â”€ customer_profile.csv
â”‚   â”œâ”€â”€ marketing/
â”‚   â”‚   â”œâ”€â”€ campaigns.csv
â”‚   â”‚   â”œâ”€â”€ assets.csv
â”‚   â”‚   â”œâ”€â”€ audiences.csv
â”‚   â”‚   â”œâ”€â”€ sends.csv
â”‚   â”‚   â””â”€â”€ events.csv
â”‚   â”œâ”€â”€ commerce/
â”‚   â”‚   â”œâ”€â”€ products.csv
â”‚   â”‚   â”œâ”€â”€ orders.csv
â”‚   â”‚   â”œâ”€â”€ order_lines.csv
â”‚   â”‚   â””â”€â”€ returns.csv
â”‚   â””â”€â”€ text/
â”‚       â”œâ”€â”€ customer_knowledge_notes/
â”‚       â”‚   â”œâ”€â”€ CUST_000001.txt
â”‚       â”‚   â”œâ”€â”€ CUST_000002.txt
â”‚       â”‚   â””â”€â”€ ... (20 000 fichiers)
â”‚       â””â”€â”€ email_bodies/
â”‚           â”œâ”€â”€ ASSET_001.txt
â”‚           â”œâ”€â”€ ASSET_002.txt
â”‚           â””â”€â”€ ... (60 fichiers)
```

### 2.2 Upload via l'Interface Fabric

**Option A : Upload direct (pour petits volumes)**

1. Dans le Lakehouse, aller dans **Files**
2. CrÃ©er une structure de dossiers :
   - Cliquer sur **Upload** â†’ **Upload folder**
   - SÃ©lectionner `data/raw/crm`
   - RÃ©pÃ©ter pour `data/raw/marketing`, `data/raw/commerce`, et `data/raw/text`

**Option B : Upload via OneLake File Explorer (recommandÃ©)**

1. Installer [OneLake File Explorer](https://www.microsoft.com/en-us/download/details.aspx?id=105222) (Windows uniquement)
2. Ouvrir OneLake File Explorer
3. Naviguer vers votre workspace â†’ `Marketing360_Lakehouse` â†’ **Files**
4. Copier-coller les dossiers `crm/`, `marketing/`, `commerce/`, et `text/` depuis votre explorateur Windows

**Option C : Upload via API/CLI (pour automatisation)**

```bash
# NÃ©cessite azcopy ou un script Azure CLI
azcopy copy "data/raw/*" "https://<onelake-path>/Files/raw/" --recursive
```

âœ… **RÃ©sultat attendu** : Structure de dossiers visible dans **Files** du Lakehouse.

---

## Ã‰tape 3 : CrÃ©er des OneLake Shortcuts

### 3.1 Principe des Shortcuts

Les **OneLake Shortcuts** crÃ©ent des liens symboliques sans duplication de donnÃ©es.
Ils permettent de "monter" des donnÃ©es externes (ADLS, S3, etc.) ou internes (autre Lakehouse).

**Pour cette dÃ©mo** : On va crÃ©er des shortcuts vers les fichiers uploadÃ©s (optionnel si dÃ©jÃ  dans le Lakehouse, mais utile pour dÃ©montrer la fonctionnalitÃ©).

### 3.2 CrÃ©er un Shortcut (Exemple : CSV CRM)

1. Dans le Lakehouse, section **Files**
2. Clic droit sur la racine â†’ **New shortcut**
3. Choisir **OneLake** (pour lier des fichiers dÃ©jÃ  dans Fabric)
4. SÃ©lectionner :
   - **Workspace** : Demo-Marketing360
   - **Item** : Marketing360_Lakehouse
   - **Path** : `Files/raw/crm`
5. Nommer le shortcut : `crm_data`
6. Cliquer sur **Create**

RÃ©pÃ©ter pour `marketing`, `commerce`, et `text` si vous voulez dÃ©montrer plusieurs shortcuts.

> **Note** : Si les fichiers sont dÃ©jÃ  dans le Lakehouse, cette Ã©tape est conceptuelle pour la dÃ©mo. 
> Dans un scÃ©nario rÃ©el, les shortcuts pointeraient vers un storage externe (ADLS Gen2, S3, etc.).

âœ… **RÃ©sultat attendu** : IcÃ´ne de shortcut visible dans Files, sans duplication de donnÃ©es.

---

## Ã‰tape 4 : Appliquer Shortcut Transformations AI sur les Textes

### 4.1 Principe des Shortcut Transformations

**Shortcut Transformations AI** (preview) transforme automatiquement des fichiers non structurÃ©s (txt, pdf, images) en tables Delta queryables.

Pour les fichiers texte (customer knowledge notes + email bodies), Fabric peut extraire :
- **Sentiment** (positif/neutre/nÃ©gatif)
- **RÃ©sumÃ©** (summary du contenu)
- **PII Detection** (emails, tÃ©lÃ©phones, noms)
- **Entity Extraction** (organisations, produits, montants)
- **Topics** (sujets dÃ©tectÃ©s)

### 4.2 CrÃ©er une Transformation AI pour Customer Knowledge Notes

1. Dans le Lakehouse, aller dans **Files** â†’ `raw/text/customer_knowledge_notes/`
2. Clic droit sur le dossier `customer_knowledge_notes` â†’ **New AI transformation** (ou **Apply AI skills**)
   - Si l'option n'est pas visible, vÃ©rifier que la preview est activÃ©e dans les paramÃ¨tres du tenant
3. Configurer la transformation :
   - **Source** : `customer_knowledge_notes/` (tous les .txt)
   - **Destination** : Table Delta `customer_knowledge_transformed`
   - **AI Skills Ã  appliquer** :
     - âœ… Sentiment Analysis
     - âœ… Summarization
     - âœ… PII Detection
     - âœ… Entity Extraction
     - âœ… Key Phrase Extraction
4. Cliquer sur **Create transformation**

### 4.3 CrÃ©er une Transformation AI pour Email Bodies

1. Dans le Lakehouse, aller dans **Files** â†’ `raw/text/email_bodies/`
2. Clic droit sur le dossier `email_bodies` â†’ **New AI transformation**
3. Configurer la transformation :
   - **Source** : `email_bodies/` (tous les .txt)
   - **Destination** : Table Delta `email_bodies_transformed`
   - **AI Skills Ã  appliquer** :
     - âœ… Sentiment Analysis
     - âœ… Summarization
     - âœ… PII Detection
     - âœ… Key Phrase Extraction
4. Cliquer sur **Create transformation**

### 4.4 ExÃ©cuter les Transformations

1. Les transformations se lancent automatiquement
2. Suivre le progrÃ¨s dans le **Monitoring** (Activity pane)
3. Temps estimÃ© : 
   - Customer knowledge notes : 15-20 minutes pour 20 000 fichiers
   - Email bodies : 2-3 minutes pour 60 fichiers

âœ… **RÃ©sultat attendu** : Deux nouvelles tables Delta `customer_knowledge_transformed` et `email_bodies_transformed` apparaissent dans **Tables**.

### 4.5 VÃ©rifier le SchÃ©ma des Tables TransformÃ©es

**Table `customer_knowledge_transformed`**

Colonnes attendues :
- `customer_id` (extrait du nom de fichier CUST_XXXXXX)
- `content` (texte complet de la note)
- `summary` (rÃ©sumÃ© gÃ©nÃ©rÃ©)
- `sentiment` (positive/neutral/negative)
- `sentiment_score` (0-1)
- `pii_detected` (liste des PII trouvÃ©es)
- `entities_detected` (organisations, produits, montants)
- `key_phrases` (sujets principaux)
- `_metadata` (informations systÃ¨me)

**Table `email_bodies_transformed`**

Colonnes attendues :
- `asset_id` (extrait du nom de fichier ASSET_XXX)
- `content` (texte complet de l'email)
- `summary` (rÃ©sumÃ© gÃ©nÃ©rÃ©)
- `sentiment` (positive/neutral/negative)
- `sentiment_score` (0-1)
- `key_phrases` (sujets principaux)
- `_metadata` (informations systÃ¨me)

**Exemple de requÃªte test** :
```sql
-- VÃ©rifier les notes clients
SELECT customer_id, sentiment, LEFT(summary, 100) AS summary_preview, pii_detected
FROM customer_knowledge_transformed
LIMIT 10;

-- VÃ©rifier les emails
SELECT asset_id, sentiment, LEFT(summary, 100) AS summary_preview
FROM email_bodies_transformed
LIMIT 10;
```

> **Troubleshooting** : Si les tables n'apparaissent pas, rafraÃ®chir le Lakehouse ou vÃ©rifier les logs de transformation.

---

## Ã‰tape 5 : Charger les CSV en Tables Delta

### 5.1 CrÃ©er des Tables depuis les CSV

Pour chaque fichier CSV, crÃ©er une table Delta.

**MÃ©thode A : Via l'interface (pour dÃ©mo interactive)**

1. Dans **Files**, naviguer vers `raw/crm/customers.csv`
2. Clic droit â†’ **Load to new table**
3. Configurer :
   - **Table name** : `crm_customers`
   - **Delimiter** : Comma
   - **First row has headers** : âœ… Yes
   - **Infer schema** : âœ… Yes
4. Cliquer sur **Load**

RÃ©pÃ©ter pour toutes les tables :

**Tables CRM (6)** :
- `crm_accounts` (accounts.csv)
- `crm_customers` (customers.csv)
- `crm_segments` (segments.csv)
- `crm_customer_segments` (customer_segments.csv)
- `crm_interactions` (interactions.csv)
- `crm_customer_profile` (customer_profile.csv)

**Tables Marketing (5)** :
- `marketing_campaigns` (campaigns.csv)
- `marketing_assets` (assets.csv)
- `marketing_audiences` (audiences.csv)
- `marketing_sends` (sends.csv)
- `marketing_events` (events.csv)

**Tables Commerce (4)** :
- `products` (products.csv)
- `orders` (orders.csv)
- `order_lines` (order_lines.csv)
- `returns` (returns.csv)

**MÃ©thode B : Via Notebook (pour automatisation)**

CrÃ©er un Notebook dans le Lakehouse :

```python
# Notebook: Load CSV to Delta Tables

from pyspark.sql import SparkSession

# Chemins des fichiers CRM
crm_files = {
    "crm_accounts": "Files/raw/crm/accounts.csv",
    "crm_customers": "Files/raw/crm/customers.csv",
    "crm_segments": "Files/raw/crm/segments.csv",
    "crm_customer_segments": "Files/raw/crm/customer_segments.csv",
    "crm_interactions": "Files/raw/crm/interactions.csv",
    "crm_customer_profile": "Files/raw/crm/customer_profile.csv"
}

# Chemins des fichiers Marketing
marketing_files = {
    "marketing_campaigns": "Files/raw/marketing/campaigns.csv",
    "marketing_assets": "Files/raw/marketing/assets.csv",
    "marketing_audiences": "Files/raw/marketing/audiences.csv",
    "marketing_sends": "Files/raw/marketing/sends.csv",
    "marketing_events": "Files/raw/marketing/events.csv"
}

# Chemins des fichiers Commerce
commerce_files = {
    "products": "Files/raw/commerce/products.csv",
    "orders": "Files/raw/commerce/orders.csv",
    "order_lines": "Files/raw/commerce/order_lines.csv",
    "returns": "Files/raw/commerce/returns.csv"
}

# Fusionner tous les fichiers
all_files = {**crm_files, **marketing_files, **commerce_files}

# Charger chaque CSV en table Delta
for table_name, file_path in all_files.items():
    df = spark.read.csv(file_path, header=True, inferSchema=True)
    df.write.format("delta").mode("overwrite").saveAsTable(table_name)
    print(f"âœ… Table {table_name} crÃ©Ã©e avec {df.count()} lignes")
```

ExÃ©cuter le notebook (Ctrl+Enter sur chaque cellule).

âœ… **RÃ©sultat attendu** : 15 tables CSV + 2 tables AI transformÃ©es = **17 tables au total** dans **Tables**.

### 5.2 VÃ©rifier les Types de DonnÃ©es

Quelques vÃ©rifications importantes :

```sql
-- VÃ©rifier que les dates sont bien en TIMESTAMP
DESCRIBE crm_customers;
-- Attendu: first_seen_at TIMESTAMP

DESCRIBE orders;
-- Attendu: order_date TIMESTAMP

DESCRIBE marketing_sends;
-- Attendu: sent_at TIMESTAMP

-- VÃ©rifier les nombres
DESCRIBE order_lines;
-- Attendu: quantity INT, unit_price DECIMAL, total_price DECIMAL

DESCRIBE crm_customer_profile;
-- Attendu: clv_score FLOAT, churn_risk_score INT
```

Si les types sont incorrects (ex: date en STRING), ajuster avec :

```python
from pyspark.sql.functions import to_timestamp, col

# Corriger les timestamps des orders
df = spark.table("orders")
df = df.withColumn("order_date", to_timestamp(col("order_date"), "yyyy-MM-dd HH:mm:ss"))
df.write.format("delta").mode("overwrite").option("overwriteSchema", "true").saveAsTable("orders")

# Corriger les timestamps des marketing_sends
df = spark.table("marketing_sends")
df = df.withColumn("sent_at", to_timestamp(col("sent_at"), "yyyy-MM-dd HH:mm:ss"))
df.write.format("delta").mode("overwrite").option("overwriteSchema", "true").saveAsTable("marketing_sends")
```

---

## Ã‰tape 6 : CrÃ©er un Semantic Model

Le **Semantic Model** (ex-Analysis Services) structure les donnÃ©es pour Power BI et le Data Agent.

### 6.1 CrÃ©er le Semantic Model

1. Dans le Lakehouse, cliquer sur **New semantic model** (en haut Ã  droite)
2. Nom : `Marketing360_Model`
3. SÃ©lectionner les tables Ã  inclure :
   - âœ… **CRM** : crm_accounts, crm_customers, crm_segments, crm_customer_segments, crm_interactions, crm_customer_profile
   - âœ… **Marketing** : marketing_campaigns, marketing_assets, marketing_audiences, marketing_sends, marketing_events
   - âœ… **Commerce** : products, orders, order_lines, returns
   - âœ… **AI Transformed** : customer_knowledge_transformed, email_bodies_transformed
4. Cliquer sur **Confirm**

### 6.2 DÃ©finir les Relations

Ouvrir le Semantic Model et crÃ©er les relations :

1. Cliquer sur **Model view** (icÃ´ne diagramme)
2. CrÃ©er les relations suivantes (drag & drop entre tables) :

**Relations CRM**

| Table From | Colonne From | Table To | Colonne To | CardinalitÃ© |
|------------|--------------|----------|------------|-------------|
| `crm_customers` | `account_id` | `crm_accounts` | `account_id` | Many-to-One |
| `crm_customer_segments` | `customer_id` | `crm_customers` | `customer_id` | Many-to-One |
| `crm_customer_segments` | `segment_id` | `crm_segments` | `segment_id` | Many-to-One |
| `crm_interactions` | `customer_id` | `crm_customers` | `customer_id` | Many-to-One |
| `crm_customer_profile` | `customer_id` | `crm_customers` | `customer_id` | One-to-One |

**Relations Marketing**

| Table From | Colonne From | Table To | Colonne To | CardinalitÃ© |
|------------|--------------|----------|------------|-------------|
| `marketing_assets` | `campaign_id` | `marketing_campaigns` | `campaign_id` | Many-to-One |
| `marketing_audiences` | `campaign_id` | `marketing_campaigns` | `campaign_id` | Many-to-One |
| `marketing_audiences` | `segment_id` | `crm_segments` | `segment_id` | Many-to-One |
| `marketing_sends` | `campaign_id` | `marketing_campaigns` | `campaign_id` | Many-to-One |
| `marketing_sends` | `asset_id` | `marketing_assets` | `asset_id` | Many-to-One |
| `marketing_sends` | `customer_id` | `crm_customers` | `customer_id` | Many-to-One |
| `marketing_events` | `send_id` | `marketing_sends` | `send_id` | Many-to-One |

**Relations Commerce**

| Table From | Colonne From | Table To | Colonne To | CardinalitÃ© |
|------------|--------------|----------|------------|-------------|
| `orders` | `customer_id` | `crm_customers` | `customer_id` | Many-to-One |
| `order_lines` | `order_id` | `orders` | `order_id` | Many-to-One |
| `order_lines` | `product_id` | `products` | `product_id` | Many-to-One |
| `returns` | `order_id` | `orders` | `order_id` | Many-to-One |

**Relations AI Transformed**

| Table From | Colonne From | Table To | Colonne To | CardinalitÃ© |
|------------|--------------|----------|------------|-------------|
| `customer_knowledge_transformed` | `customer_id` | `crm_customers` | `customer_id` | Many-to-One (*) |
| `email_bodies_transformed` | `asset_id` | `marketing_assets` | `asset_id` | One-to-One (*) |

(*) Ces relations dÃ©pendent de la qualitÃ© de l'extraction des IDs par l'AI. VÃ©rifier que les IDs sont correctement parsÃ©s.

### 6.3 CrÃ©er des Mesures DAX

Dans le Semantic Model, aller dans **Data view** et crÃ©er une **New measure** :

```dax
// ============================================
// Mesures CRM
// ============================================

Total Customers = COUNTROWS(crm_customers)

Active Customers = 
CALCULATE(
    [Total Customers],
    crm_customers[status] = "active"
)

Churned Customers = 
CALCULATE(
    [Total Customers],
    crm_customers[status] = "churned"
)

Churn Rate % = 
DIVIDE(
    [Churned Customers],
    [Total Customers],
    0
) * 100

Avg CLV = AVERAGE(crm_customer_profile[clv_score])

Avg Churn Risk = AVERAGE(crm_customer_profile[churn_risk_score])

Avg NPS = AVERAGE(crm_customer_profile[nps_last])

Total Interactions = COUNTROWS(crm_interactions)

Avg Satisfaction = AVERAGE(crm_interactions[satisfaction_score])

// ============================================
// Mesures Marketing
// ============================================

Total Campaigns = COUNTROWS(marketing_campaigns)

Active Campaigns = 
CALCULATE(
    [Total Campaigns],
    marketing_campaigns[status] = "active"
)

Total Marketing Budget = SUM(marketing_campaigns[budget_eur])

Total Email Sends = COUNTROWS(marketing_sends)

Total Email Events = COUNTROWS(marketing_events)

// Taux d'ouverture
Email Opens = 
CALCULATE(
    [Total Email Events],
    marketing_events[event_type] = "open"
)

Open Rate % = 
DIVIDE(
    [Email Opens],
    [Total Email Sends],
    0
) * 100

// Taux de clic
Email Clicks = 
CALCULATE(
    [Total Email Events],
    marketing_events[event_type] = "click"
)

Click Rate % = 
DIVIDE(
    [Email Clicks],
    [Total Email Sends],
    0
) * 100

// Taux de bounce
Email Bounces = 
CALCULATE(
    [Total Email Events],
    marketing_events[event_type] = "bounce"
)

Bounce Rate % = 
DIVIDE(
    [Email Bounces],
    [Total Email Sends],
    0
) * 100

// Taux de dÃ©sinscription
Email Unsubscribes = 
CALCULATE(
    [Total Email Events],
    marketing_events[event_type] = "unsubscribe"
)

Unsubscribe Rate % = 
DIVIDE(
    [Email Unsubscribes],
    [Total Email Sends],
    0
) * 100

// ============================================
// Mesures Commerce
// ============================================

Total Orders = COUNTROWS(orders)

Total Revenue = 
SUMX(
    order_lines,
    order_lines[quantity] * order_lines[unit_price] * (1 - order_lines[discount])
)

Avg Order Value = DIVIDE([Total Revenue], [Total Orders])

Total Returns = COUNTROWS(returns)

Return Rate % = 
DIVIDE(
    [Total Returns],
    [Total Orders],
    0
) * 100

Total Products Sold = SUM(order_lines[quantity])

// ============================================
// Mesures d'Attribution Marketing
// ============================================

// Orders attributed to marketing (last-touch attribution)
Marketing Attributed Orders = 
CALCULATE(
    [Total Orders],
    orders[attribution_source] = "marketing"
)

Marketing Attributed Revenue = 
CALCULATE(
    [Total Revenue],
    orders[attribution_source] = "marketing"
)

// ROI Marketing
Marketing ROI % = 
DIVIDE(
    [Marketing Attributed Revenue] - [Total Marketing Budget],
    [Total Marketing Budget],
    0
) * 100

// ============================================
// Mesures CombinÃ©es Customer 360
// ============================================

Revenue per Customer = 
DIVIDE(
    [Total Revenue],
    [Total Customers],
    0
)

Orders per Customer = 
DIVIDE(
    [Total Orders],
    [Total Customers],
    0
)

Customers Who Ordered = 
CALCULATE(
    DISTINCTCOUNT(orders[customer_id])
)

Conversion Rate % = 
DIVIDE(
    [Customers Who Ordered],
    [Total Customers],
    0
) * 100

// ============================================
// Mesures Temporelles
// ============================================

Revenue YTD = 
TOTALYTD(
    [Total Revenue],
    orders[order_date]
)

Orders MTD = 
TOTALMTD(
    [Total Orders],
    orders[order_date]
)
```

### 6.4 Publier le Semantic Model

1. Cliquer sur **File** â†’ **Save**
2. Le modÃ¨le est automatiquement publiÃ© dans le workspace

âœ… **RÃ©sultat attendu** : Semantic Model disponible dans le workspace, prÃªt pour Power BI et Data Agent.

---

## Ã‰tape 7 : Configurer le Fabric Data Agent

### 7.1 Activer la Preview Data Agent

1. Aller dans **Settings** (âš™ï¸) â†’ **Tenant settings** â†’ **Admin Portal**
2. Rechercher **Fabric Data Agent** (ou **Copilot for Data**)
3. Activer la preview pour le workspace

### 7.2 CrÃ©er le Data Agent

1. Dans le workspace, cliquer sur **+ New** â†’ **Data Agent** (ou **Copilot**)
2. Nom : `Marketing360_Agent`
3. SÃ©lectionner la source :
   - **Type** : Semantic Model
   - **Source** : `Marketing360_Model`
4. Cliquer sur **Create**

### 7.3 Configurer les Instructions (System Prompt)

1. Ouvrir le Data Agent
2. Aller dans **Settings** â†’ **Instructions**
3. Coller le contenu de [`data_agent_instructions.md`](data_agent_instructions.md)
4. Sauvegarder

### 7.4 Tester le Data Agent

Poser une premiÃ¨re question :
```
Combien de clients avons-nous au total ?
```

RÃ©ponse attendue : `20 000 clients`

Si la rÃ©ponse est correcte âœ…, passer Ã  l'Ã©tape 8.

Si la rÃ©ponse est incorrecte âŒ :
- VÃ©rifier que le Semantic Model est bien publiÃ©
- VÃ©rifier les relations entre tables
- VÃ©rifier que les instructions sont bien configurÃ©es

---

## Ã‰tape 8 : Tester et Valider

### 8.1 Questions de Validation

Poser les questions de [`questions_demo.md`](questions_demo.md).

**Exemples de questions Ã  tester** :

1. âœ… Combien de clients avons-nous au total ?
2. âœ… Quel est le taux de churn actuel ?
3. âœ… Quelle est la CLV moyenne de nos clients ?
4. âœ… Combien de campagnes marketing sont actives ?
5. âœ… Quel est le taux d'ouverture moyen des emails ?
6. âœ… Quel est le taux de clic moyen des emails ?
7. âœ… Quel est le ROI marketing global ?
8. âœ… Quelle campagne a gÃ©nÃ©rÃ© le plus de revenu ?
9. âœ… Quels segments sont les plus rentables ?
10. âœ… Quel est le panier moyen ?

**CritÃ¨re de succÃ¨s** : Au moins 80% des questions fonctionnent correctement.

### 8.2 CrÃ©er un Dashboard Power BI

1. Dans le workspace, cliquer sur **+ New** â†’ **Report**
2. SÃ©lectionner `Marketing360_Model` comme source
3. CrÃ©er quelques visuels rapides :
   
**Page 1 : Vue d'Ensemble**
   - Card : Total Customers, Active Customers, Churn Rate %
   - Card : Total Revenue, Total Orders, Avg Order Value
   - Donut : Customers by Lifecycle Stage
   - Line Chart : Revenue by Month

**Page 2 : Marketing Performance**
   - Card : Total Campaigns, Total Email Sends, Total Marketing Budget
   - Card : Open Rate %, Click Rate %, Marketing ROI %
   - Bar Chart : Email Events by Type (open, click, bounce, unsubscribe)
   - Table : Top Campaigns by Revenue

**Page 3 : Customer 360**
   - Scatter Chart : CLV Score vs Churn Risk Score
   - Bar Chart : Customers by Segment
   - Table : Top Customers by CLV
   - Line Chart : Avg NPS over Time

4. Sauvegarder le rapport : `Marketing360_Dashboard`

### 8.3 VÃ©rifier les Permissions

Si la dÃ©mo doit Ãªtre partagÃ©e :
1. Aller dans **Workspace settings** â†’ **Access**
2. Ajouter les viewers/contributors selon les besoins
3. VÃ©rifier que le Semantic Model est partagÃ© (hÃ©rite des permissions du workspace)

---

## ðŸŽ‰ DÃ©ploiement TerminÃ©

Vous avez maintenant :
- âœ… Un Lakehouse avec 17 tables Delta (15 CSV + 2 AI transformed)
- âœ… Des OneLake Shortcuts (optionnel)
- âœ… Des AI Transformations sur les customer knowledge notes et email bodies
- âœ… Un Semantic Model complet avec relations et mesures
- âœ… Un Data Agent fonctionnel
- âœ… Un dashboard Power BI multi-pages

**Prochaines Ã©tapes** :
- Tester toutes les questions de la dÃ©mo ([questions_demo.md](questions_demo.md))
- Personnaliser le dashboard Power BI
- PrÃ©parer le pitch de prÃ©sentation ([demo_story.md](demo_story.md))
- Explorer les insights des AI transformations

---

## ðŸ”§ Troubleshooting

### ProblÃ¨me : Les fichiers texte ne sont pas transformÃ©s

**SymptÃ´mes** : Les tables `customer_knowledge_transformed` ou `email_bodies_transformed` n'existent pas

**Solutions** :
1. VÃ©rifier que la preview **Shortcut Transformations AI** est activÃ©e
2. VÃ©rifier que les fichiers .txt sont bien prÃ©sents dans `Files/raw/text/`
3. RÃ©essayer la transformation manuellement
4. VÃ©rifier les quotas du tenant (limitations preview)
5. Pour les 20 000 fichiers customer knowledge notes, vÃ©rifier que le traitement ne timeout pas (peut nÃ©cessiter de traiter par batch)

**Alternative** : CrÃ©er une table simplifiÃ©e manuellement avec un Notebook :

```python
import os
from pyspark.sql.types import StructType, StructField, StringType

# Lire tous les fichiers customer knowledge notes
notes = []
files_path = "/lakehouse/default/Files/raw/text/customer_knowledge_notes/"

for file in os.listdir(files_path):
    if file.endswith(".txt"):
        with open(os.path.join(files_path, file), "r", encoding="utf-8") as f:
            content = f.read()
            customer_id = file.replace(".txt", "")
            notes.append({
                "customer_id": customer_id,
                "content": content,
                "summary": "Manual summary",  # Ã€ gÃ©nÃ©rer avec Azure OpenAI si besoin
                "sentiment": "neutral"  # Ã€ calculer
            })

# CrÃ©er DataFrame et table Delta
schema = StructType([
    StructField("customer_id", StringType(), False),
    StructField("content", StringType(), True),
    StructField("summary", StringType(), True),
    StructField("sentiment", StringType(), True)
])

df = spark.createDataFrame(notes, schema)
df.write.format("delta").mode("overwrite").saveAsTable("customer_knowledge_transformed")
```

---

### ProblÃ¨me : Le Data Agent ne rÃ©pond pas correctement

**SymptÃ´mes** : RÃ©ponses incohÃ©rentes ou erreurs

**Solutions** :
1. VÃ©rifier que le Semantic Model est publiÃ© (statut "Active")
2. VÃ©rifier les relations entre tables (doivent Ãªtre correctes)
3. VÃ©rifier que toutes les mesures DAX sont bien calculÃ©es (pas d'erreur)
4. Simplifier la question (utiliser des termes exacts des colonnes)
5. Consulter les instructions du Data Agent et ajuster si nÃ©cessaire
6. VÃ©rifier les logs d'erreur dans **Monitoring**

**Exemple** :
- âŒ "Quel est le taux de conversion des emails ?" (ambigu : click ou order ?)
- âœ… "Quel est le taux de clic des emails ?" (terme exact : `Click Rate %`)

---

### ProblÃ¨me : Erreurs de type de donnÃ©es

**SymptÃ´mes** : Les dates sont en texte, les calculs Ã©chouent

**Solutions** :
1. RÃ©importer les CSV avec `inferSchema=True` (Notebook)
2. Caster manuellement les colonnes :

```python
from pyspark.sql.functions import to_timestamp, col

# Corriger les timestamps des orders
df = spark.table("orders")
df = df.withColumn("order_date", to_timestamp(col("order_date"), "yyyy-MM-dd HH:mm:ss"))
df.write.format("delta").mode("overwrite").option("overwriteSchema", "true").saveAsTable("orders")

# Corriger les timestamps des marketing_sends
df = spark.table("marketing_sends")
df = df.withColumn("sent_at", to_timestamp(col("sent_at"), "yyyy-MM-dd HH:mm:ss"))
df.write.format("delta").mode("overwrite").option("overwriteSchema", "true").saveAsTable("marketing_sends")

# Corriger les timestamps des crm_interactions
df = spark.table("crm_interactions")
df = df.withColumn("occurred_at", to_timestamp(col("occurred_at"), "yyyy-MM-dd HH:mm:ss"))
df.write.format("delta").mode("overwrite").option("overwriteSchema", "true").saveAsTable("crm_interactions")
```

3. VÃ©rifier l'encodage UTF-8 des CSV (pas de BOM)

---

### ProblÃ¨me : Relations Many-to-Many non supportÃ©es

**SymptÃ´mes** : Erreur lors de la crÃ©ation de relations entre `crm_customer_segments` et autres tables

**Solution** :
Les relations Many-to-Many sont supportÃ©es dans les Semantic Models rÃ©cents. Si vous rencontrez des problÃ¨mes :
1. VÃ©rifier que vous utilisez la derniÃ¨re version du Semantic Model
2. CrÃ©er des tables de pont (bridge tables) si nÃ©cessaire
3. Utiliser des relations inactives et les activer dans les mesures DAX avec `USERELATIONSHIP()`

---

### ProblÃ¨me : Performance lente du Data Agent

**SymptÃ´mes** : RÃ©ponses lentes (>30 secondes)

**Solutions** :
1. Optimiser les mesures DAX (Ã©viter les calculs complexes en nested)
2. CrÃ©er des agrÃ©gations (aggregations) dans le Semantic Model
3. RÃ©duire le nombre de tables exposÃ©es au Data Agent
4. VÃ©rifier que les index Delta sont Ã  jour
5. Utiliser des tables prÃ©calculÃ©es pour les KPIs principaux

---

### ProblÃ¨me : Permissions insuffisantes

**SymptÃ´mes** : "Access denied" ou "Not authorized"

**Solutions** :
1. VÃ©rifier que vous Ãªtes **Admin** ou **Member** du workspace
2. VÃ©rifier les permissions sur le Lakehouse (doit Ãªtre partagÃ©)
3. VÃ©rifier les permissions sur le Semantic Model (hÃ©rite du workspace par dÃ©faut)
4. VÃ©rifier que la licence Fabric est active

---

## ðŸ“š Ressources ComplÃ©mentaires

- [Documentation OneLake Shortcuts](https://learn.microsoft.com/en-us/fabric/onelake/onelake-shortcuts)
- [AI Transformations in Fabric](https://learn.microsoft.com/en-us/fabric/data-engineering/ai-transformations)
- [Fabric Data Agent (Copilot)](https://learn.microsoft.com/en-us/fabric/data-science/data-agent)
- [Semantic Model Best Practices](https://learn.microsoft.com/en-us/power-bi/guidance/star-schema)
- [DAX Formulas Reference](https://learn.microsoft.com/en-us/dax/)
- [Marketing Analytics Patterns](https://learn.microsoft.com/en-us/power-bi/guidance/star-schema#marketing-analytics)

---

## âœ… Checklist de DÃ©ploiement

Cochez au fur et Ã  mesure :

- [ ] Lakehouse crÃ©Ã©
- [ ] DonnÃ©es uploadÃ©es (15 CSV + 20 060 fichiers texte)
- [ ] OneLake Shortcuts crÃ©Ã©s (optionnel)
- [ ] AI Transformations appliquÃ©es sur customer knowledge notes
- [ ] AI Transformations appliquÃ©es sur email bodies
- [ ] 17 tables Delta crÃ©Ã©es et vÃ©rifiÃ©es (15 CSV + 2 AI)
- [ ] Semantic Model crÃ©Ã©
- [ ] Relations CRM dÃ©finies (5 relations)
- [ ] Relations Marketing dÃ©finies (7 relations)
- [ ] Relations Commerce dÃ©finies (4 relations)
- [ ] Relations AI Transformed dÃ©finies (2 relations)
- [ ] Mesures DAX ajoutÃ©es (CRM, Marketing, Commerce, Attribution)
- [ ] Data Agent configurÃ©
- [ ] Instructions du Data Agent ajoutÃ©es
- [ ] Questions de test validÃ©es (â‰¥80%)
- [ ] Dashboard Power BI crÃ©Ã© (3 pages)
- [ ] Permissions partagÃ©es (si nÃ©cessaire)

**Si toutes les cases sont cochÃ©es, la dÃ©mo est prÃªte ! ðŸš€**

---

## ðŸ’¡ Cas d'Usage AvancÃ©s

### Analyse d'Attribution Marketing

Utiliser les donnÃ©es pour rÃ©pondre Ã  :
- Quelle campagne a le meilleur ROI ?
- Quel segment rÃ©pond le mieux aux emails ?
- Les tests A/B apportent-ils de la valeur ?
- Quel est le dÃ©lai moyen entre l'email et l'achat ?

**RequÃªte exemple** :
```sql
-- Attribution last-touch : orders dans les 7 jours aprÃ¨s un clic email
SELECT 
    mc.campaign_name,
    COUNT(DISTINCT o.order_id) AS attributed_orders,
    SUM(ol.total_price) AS attributed_revenue,
    mc.budget_eur,
    (SUM(ol.total_price) - mc.budget_eur) / mc.budget_eur * 100 AS roi_pct
FROM marketing_campaigns mc
JOIN marketing_sends ms ON mc.campaign_id = ms.campaign_id
JOIN marketing_events me ON ms.send_id = me.send_id AND me.event_type = 'click'
JOIN orders o ON ms.customer_id = o.customer_id 
    AND o.order_date BETWEEN me.occurred_at AND DATEADD(day, 7, me.occurred_at)
JOIN order_lines ol ON o.order_id = ol.order_id
GROUP BY mc.campaign_name, mc.budget_eur
ORDER BY roi_pct DESC;
```

### Analyse de Sentiment des Notes Clients

Utiliser `customer_knowledge_transformed` pour :
- Identifier les clients mÃ©contents (sentiment nÃ©gatif)
- Prioriser les interventions CRM
- CorrÃ©ler sentiment et churn risk

**RequÃªte exemple** :
```sql
-- Clients avec sentiment nÃ©gatif ET churn risk Ã©levÃ©
SELECT 
    c.customer_id,
    c.lifecycle_stage,
    cp.churn_risk_score,
    ck.sentiment,
    ck.summary,
    cp.total_spend_eur
FROM crm_customers c
JOIN crm_customer_profile cp ON c.customer_id = cp.customer_id
JOIN customer_knowledge_transformed ck ON c.customer_id = ck.customer_id
WHERE ck.sentiment = 'negative'
  AND cp.churn_risk_score > 70
ORDER BY cp.total_spend_eur DESC;
```

### Optimisation des Email Templates

Utiliser `email_bodies_transformed` pour :
- Analyser le sentiment des emails
- Identifier les key phrases qui performent
- Tester l'impact du tone sur l'engagement

**RequÃªte exemple** :
```sql
-- CorrÃ©lation entre sentiment de l'email et taux de clic
SELECT 
    ma.asset_name,
    eb.sentiment,
    COUNT(DISTINCT ms.send_id) AS total_sends,
    COUNT(DISTINCT CASE WHEN me.event_type = 'click' THEN me.send_id END) AS total_clicks,
    COUNT(DISTINCT CASE WHEN me.event_type = 'click' THEN me.send_id END) * 100.0 / COUNT(DISTINCT ms.send_id) AS click_rate_pct
FROM marketing_assets ma
JOIN email_bodies_transformed eb ON ma.asset_id = eb.asset_id
JOIN marketing_sends ms ON ma.asset_id = ms.asset_id
LEFT JOIN marketing_events me ON ms.send_id = me.send_id
GROUP BY ma.asset_name, eb.sentiment
ORDER BY click_rate_pct DESC;
```

---

**Happy deploying! ðŸŽ¯ðŸ“§**

*Ce guide a Ã©tÃ© crÃ©Ã© pour Microsoft Fabric et optimisÃ© pour les dÃ©mos marketing.*
